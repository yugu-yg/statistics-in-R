---
title: "Lab 9"
author: "Stat 131A"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE, fig.width = 4 * 1.2, fig.height = 3 * 1.2)

library(tidyverse)
```

Welcome to the Lab 9! In this lab, we will review PCA and implement multivariate linear regressions in `R`. 

## A simple PCA example

This is a simple example for PCA from [R Bloggers](https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/). The iris dataset is perhaps the best known dataset for classification. The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. 


```{r}
# Load data
data(iris)
head(iris, 3)
```

There are five variables in the dataset `iris`, where `Sepal.Length`, `Sepal.Width`, `Petal.Length` and `Petal.Width` are continuous and `Species` is categorical.

```{r}
names(iris)
```

### Excercise 1: PCA on the iris dataset

(a) Apply PCA to the four continuous variables. Be sure to transform these variables by taking the log and then converting those log values to standard units. __Note.__ The centering and scaling may be done by the user or by changing the arguments of `prcomp()`. See the manual page `?prcomp()` for details.

```{r}
# log transform on the four continuous variable
log.ir <- log(iris[, 1:4])
# the Species variable
ir.species <- iris[, 5]
 
# Apply PCA
# center and scale is used to standardize the variables prior to the application of PCA.
ir.pca <- prcomp(log.ir, center = TRUE, scale. = TRUE)
```

(b) Create a scatter plot of the transformed data projected onto PC1 and PC2 with PC2 on the vertical axis and PC1 on the horizontal axis. Color the points on the scatter plot by species. __Hint.__ If plotting with `plot()`, change the `col` argument.

```{r}
colorvec <- c("red", "green", "blue")
names(colorvec) = unique(ir.species)
plot(ir.pca$x[, 1], ir.pca$x[, 2], col = unname(colorvec[ir.species]), xlab =
"PC1", ylab = "PC2")
legend("topright", legend = names(colorvec), fill = unname(colorvec))
```

Now, lets add a few missing values to the data.

```{r}
iris2 <- iris
iris2[2,3] <- NA
iris2[5,2] <- NA
iris2[10,1] <- NA
```

(c) Apply PCA as before, but make change to code to omit rows with missing values.

```{r}
ir.omit <-  na.omit(log(iris2[, 1:4]))
ir2.species <- iris2[, 5]
ir2.pca <- prcomp(ir.omit, center = TRUE, scale. = TRUE)
```

(d) Project the full data (no missing values) onto the principal components space computed from the data with missingness. Create a scatter plot of the full data projected onto the space formed by PC1 and PC2 (as calculated from the data with missingness). Can you identify the species corresponding to the rows with missing data?

```{r}
ir.rot <- as.matrix(iris2[,1:4]) %*%
  ir2.pca$rotation
ir.species_with_missing <- ir2.species
ir.species_with_missing[!complete.cases(iris2)] <- NA

ir.rot %>% as.data.frame %>% ggplot(
  aes(x = PC1, y=PC2, color = ir2.species)
) + geom_point() + theme_bw()

```

(e) **Extra.** Re-create the plot from (b), but now with the `biplot()` function. Interpret the lines in the biplot: what to the lengths and directions tell you?

```{r}
```


# Multiple regression with diamond price data

This is a very large data set showing various factors of over 50,000 diamonds including price, cut, color, clarity, etc. We are interested in diamond price `price` and how different factors influence it.

| Variable   | Description                                           |
| :--------  | :---------------------------------------------------- |
| **price**  | price in US dollars (\$326–\$18,823)                  |
| **carat**  | weight of the diamond (0.2–5.01)                      |
| **cut**    | quality of the cut (Fair, Good, Very Good, Premium, Ideal) |
| **color**  | diamond colour, from J (worst) to D (best)            |
| **clarity**  | how clear the diamond is (I1 (worst), SI1, SI2, VS1, VS2, VVS1, VVS2, IF (best)) |
| **length.in.mm** | length in mm (0–10.74)                          |
| **width.of.mm** | width in mm (0–58.9)                             |
| **depth.in.mm** | depth in mm (0–31.8)                             |
| **depth**  | total depth percentage $ = z / mean(x, y) = 2 * z / (x+ y) (43–79)$ |
| **table**  | width of top of diamond relative to widest point (43–95) |




```{r}
diamonds <- read.csv("diamonds.csv")
head(diamonds)
```

### Exercise 2: Exploratory Data Analysis before Regression

First, to better understand the relationships between the variables, we will generate scatter plots. Create scatter plots between the response variable (`price`) and all the continuous variables. The function `is.numeric()` might be helpful to check whether a variable is numeric. For example:

```{r}
vec1 = 1:10
vec2 = as.character(1:10)
vec1
vec2
# The following line of code would return TRUE
is.numeric(vec1)
# The following line of code would return FALSE
is.numeric(vec2)
# The following line of code would return TRUE
is.character(vec2)
```

The function `which()` can help you to locate the column indices of the numeric vectors. (In fact, function `which()` is a super useful function in `R`.)

```{r}
# function `which` give the TRUE indices of a logical object
which(c(TRUE, FALSE, TRUE, FALSE, TRUE))
```

```{r}
# Insert your code here, use for loop to loop through each numerical variable
x=sapply(diamonds, is.numeric)
y=which(x==TRUE)
for (i in y) {
 plot(diamonds[,i], diamonds$price, ylab="Price", main=paste("price v" ,
colnames(diamonds)[i]), xlab=colnames(diamonds)[i])
}
```

## Multiple regression with continuous variable

### Exercise 3 Fit the model and Calculate the Statistics

(a) Fit a linear model to price with all the continuous variables as explanatory variables. Print the summary of your model. 

```{r}
# Insert you code here, save your model as `fit`
fit <- (lm(price ~ carat + depth + table + length.in.mm + width.of.mm+ depth.in.mm,
data = diamonds))
summary(fit)
```

(b) Calculate the fitted values.

```{r}
# Insert you code here, save your results as `fitted.values`
fitted.value <- fitted.values(fit)
```

(c) Calculate the residuals, the residual sum of squares (RSS), and the total sum of squares (TSS) using the `fitted.value()` from the above chunk.

```{r}
# Insert you code here
residual <- residuals(fit)
RSS <- sum(residual^2)
RSS
TSS <- sum(((diamonds$price) - mean(diamonds$price))^2)
TSS

```

(d) Calculate the R-square ($R^2$) using RSS and TSS. What is the interpretation of $R^2$?

```{r}
# Insert you code here, save your results as `Rsq`
Rsq <- 1-(RSS/TSS)
Rsq
```

### Exercise 4 Think deeper. Is the model reasonable?

(a) Using the fitted model, we can write the estimated model formula. _Hint._ Use `summary()` on the model object.

$$\begin{aligned}
\texttt{earnings}
& = 20849.316 + 10686.309 \cdot \texttt{carat} - 203.154 \cdot \texttt{depth} \\
& \hspace{1.5em} - 102.446 \cdot \texttt{table} - 1315.668 \cdot \texttt{length.in.mm} \\
& \hspace{1.5em}  + 66.322 \cdot \texttt{width.of.mm} + 41.628 \cdot \texttt{depth.in.mm} \\
& \hspace{1.5em}  + \hat \varepsilon
\end{aligned}$$

How do we interpret this equation? By looking at the $p$-values, we know that the coefficients we estimated are significant except for that of `depth.in.mm`. Take `length.in.mm` for example, the coefficient $-1315.668$ tells us that for a unit increase in `length.in.mm` is associated with a reduction in price of $1315.67 dollars on average. Isn't that weird? Fit another multivariate model, but this time, drop `length.in.mm`, `width.of.mm` and `depth.in.mm`? Is that a good idea? _Hint._ Check the correlation between `length.in.mm`, `width.of.mm`,  `depth.in.mm` and `carat`.

```{r}
# insert your code here
cor(diamonds[, c("length.in.mm", "width.of.mm", "depth.in.mm" ,"carat")])
```

(b) Plot the residuals from the restricted model from part (a) against the variables and calculate their correlations. Can you find any problem in your model by looking at these scatter plots? If you're asked to add some terms to improve the model, what will you do? (_Hint._ Consider the scatter plot in Exercise 1: are the relationships linear?)

```{r}
# Insert your code here, use for loop to loop through each numeric variable
x=sapply(diamonds, is.numeric)
y=which(x==TRUE)
for (i in y) {
 plot(diamonds[,i], residual,main=paste("residual v" , colnames(diamonds)[i]), 
xlab=colnames(diamonds)[i])
 print (cor(diamonds[,i], residual))
 
}
```

## Multiple regression with continuous and categorical variables

### Exercise 5

(a) Fit a linear regression model with explanatory variable `carat`, `depth`, `table`, `clarity`, `color` and `cut`.

```{r}
levels(diamonds$clarity)
levels(diamonds$color)
levels(diamonds$cut)
```


```{r}
# Insert you code here, save your model as `fit.categorical`
fit.categorical <- (lm(price ~ carat+ depth + table + as.factor(clarity) + 
as.factor(color) + as.factor(cut), data = diamonds))
summary(fit.categorical)
```

(b) Write the equation when 
	i. Clarity is VS2, color is H, and cut is Premium. Replace ??? with numerical values.
		$$\text{price} = -18171.89 + 8699.36 \cdot \text{carat} + 168.42 \cdot \text{depth} + 79.18 \cdot \text{table}$$
	ii. clarity is I1, color is D and cut is Fair. Replace ??? by numerical values.
		$$\text{price} = -60252.5 + 5553.0  \cdot \text{carat} + 734.6 \cdot \text{depth} + 158.9  \cdot \text{table}$$
		
```{r}
v1=subset(diamonds,clarity=="VS2" & color=="H" & cut=="Premium")
v1=(lm(price ~ carat + depth + table, data = v1))
summary(v1)
v2=subset(diamonds,clarity=="I1" & color=="D" & cut=="Fair")
v2=(lm(price ~ carat + depth + table, data = v2))
summary(v2)
```

		
